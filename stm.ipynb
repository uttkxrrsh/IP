{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from dictionary import *\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "# filename is test.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(file):\n",
    "    pdfFileObj = open(file, 'rb')\n",
    "    pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "    text = ''\n",
    "    num_pages = len(pdfReader.pages)\n",
    "    for i in range(num_pages):\n",
    "        pageObj = pdfReader.pages[i]\n",
    "        text += pageObj.extract_text()\n",
    "    pdfFileObj.close()\n",
    "    return text\n",
    "\n",
    "def get_string_from_list(list):\n",
    "    string = ''\n",
    "    for i in range(len(list)):\n",
    "        string += list[i]\n",
    "        if i != len(list)-1:\n",
    "            string += ' '\n",
    "    return string\n",
    "\n",
    "def filter(text):\n",
    "    token = word_tokenize(text)\n",
    "    token = [word.lower() for word in token]\n",
    "    token = [word for word in token if word.isalpha()]\n",
    "    token = [word for word in token if not word in stop_words]\n",
    "    # remoev single character\n",
    "    token = [word for word in token if len(word) > 1]\n",
    "    # remove th\n",
    "    token = [word for word in token if word != 'th']\n",
    "    for i in range(len(token)):\n",
    "        if token[i] == 'per' and token[i+1] == 'cent':\n",
    "            token[i] = 'percent'\n",
    "            token[i+1] = ''\n",
    "    token = [word for word in token if word != '']\n",
    "    return token\n",
    "\n",
    "\n",
    "def get_bigram(token):\n",
    "    token = [stemmer.stem(word) for word in token]\n",
    "    bigram = ngrams(token, 2)\n",
    "    return list(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have  a term for eg: inflation, a list of hawkish modifier for that term and a list of dovish modifier for that term, i want to search and count the number of times the term is modified by hawkish and dovish modifier in a bigram list. i want to look for the modifier in a window of 7 either side of the term.\n",
    "\n",
    "# for eg: inflation is modified by hawkish modifier like 'rising' and dovish modifier like 'falling' in the text file. i want to count the number of times inflation is modified by hawkish and dovish modifier in the bigram list.\n",
    "# the term rising and falling can be in a window of 7 either side of the term inflation.\n",
    "\n",
    "def searchAndCountHawkish(bigram_list, term, hawkish_list):\n",
    "    count = 0\n",
    "    for i in range(len(bigram_list)):\n",
    "        if term in bigram_list[i]:\n",
    "            for j in range(len(hawkish_list)):\n",
    "                if i-7 < 0:\n",
    "                    for k in range(i+7):\n",
    "                        if hawkish_list[j] in bigram_list[k]:\n",
    "                            count += 1\n",
    "                elif i+7 > len(bigram_list):\n",
    "                    for k in range(i, len(bigram_list)):\n",
    "                        if hawkish_list[j] in bigram_list[k]:\n",
    "                            count += 1\n",
    "                else:\n",
    "                    for k in range(i-7, i+7):\n",
    "                        if hawkish_list[j] in bigram_list[k]:\n",
    "                            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchAndCountDovish(bigram_list, term, dovish_list):\n",
    "    count = 0\n",
    "    for i in range(len(bigram_list)):\n",
    "        if term in bigram_list[i]:\n",
    "            for j in range(len(dovish_list)):\n",
    "                if i-7 < 0:\n",
    "                    for k in range(i+7):\n",
    "                        if dovish_list[j] in bigram_list[k]:\n",
    "                            count += 1\n",
    "                elif i+7 > len(bigram_list):\n",
    "                    for k in range(i, len(bigram_list)):\n",
    "                        if dovish_list[j] in bigram_list[k]:\n",
    "                            count += 1\n",
    "                else:\n",
    "                    for k in range(i-7, i+7):\n",
    "                        if dovish_list[j] in bigram_list[k]:\n",
    "                            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karti\\OneDrive\\Desktop\\IP\\IP\\stm.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/OneDrive/Desktop/IP/IP/stm.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bigram_list \u001b[39m=\u001b[39m get_bigram(token)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karti/OneDrive/Desktop/IP/IP/stm.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m term \u001b[39m=\u001b[39m stemmer\u001b[39m.\u001b[39mstem(\u001b[39m'\u001b[39m\u001b[39minflation\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karti/OneDrive/Desktop/IP/IP/stm.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m wordcloud \u001b[39m=\u001b[39m WordCloud(width\u001b[39m=\u001b[39;49m\u001b[39m1600\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m, max_font_size\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\u001b[39m.\u001b[39;49mgenerate(string_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/OneDrive/Desktop/IP/IP/stm.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/karti/OneDrive/Desktop/IP/IP/stm.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(wordcloud, interpolation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[0;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\wordcloud\\wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    505\u001b[0m transposed_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mTransposedFont(\n\u001b[0;32m    506\u001b[0m     font, orientation\u001b[39m=\u001b[39morientation)\n\u001b[0;32m    507\u001b[0m \u001b[39m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m box_size \u001b[39m=\u001b[39m draw\u001b[39m.\u001b[39;49mtextbbox((\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m), word, font\u001b[39m=\u001b[39;49mtransposed_font, anchor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    509\u001b[0m \u001b[39m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    510\u001b[0m result \u001b[39m=\u001b[39m occupancy\u001b[39m.\u001b[39msample_position(box_size[\u001b[39m3\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[0;32m    511\u001b[0m                                    box_size[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[0;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(font, ImageFont\u001b[39m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly supported for TrueType fonts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m embedded_color \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "text = get_text('test.pdf')\n",
    "token = filter(text)\n",
    "string_list = get_string_from_list(token)\n",
    "bigram_list = get_bigram(token)\n",
    "term = stemmer.stem('inflation')\n",
    "\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(string_list)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_hawkish = searchAndCountHawkish(bigram_list, term, ConsumerPricesInflation_Hawkish)\n",
    "# print(cpi_hawkish)\n",
    "cpi_dovish = searchAndCountDovish(bigram_list, term, ConsumerPricesInflation_Dovish)\n",
    "# print(cpi_dovish)\n",
    "\n",
    "ip_hawkish = searchAndCountHawkish(bigram_list, term, InflationPressure_Hawkish)\n",
    "# print(ip_hawkish)\n",
    "ip_dovish = searchAndCountDovish(bigram_list, term, InflationPressure_Dovish)\n",
    "# print(ip_dovish)\n",
    "\n",
    "cs_hawkish = searchAndCountHawkish(bigram_list, term, ConsumerSpending_Hawkish)\n",
    "# print(cs_hawkish)\n",
    "cs_dovish = searchAndCountDovish(bigram_list, term, ConsumerSpending_Dovish)\n",
    "# print(cs_dovish)\n",
    "\n",
    "ea_hawkish = searchAndCountHawkish(bigram_list, term, EconomicActivity_Hawkish)\n",
    "# print(ea_hawkish)\n",
    "ea_dovish = searchAndCountDovish(bigram_list, term, EconomicActivity_Dovish)\n",
    "# print(ea_dovish)\n",
    "\n",
    "ru_hawkish = searchAndCountHawkish(bigram_list, term, ResourceUtilization_Hawkish)\n",
    "# print(ru_hawkish)\n",
    "ru_dovish = searchAndCountDovish(bigram_list, term, ResourceUtilization_Dovish)\n",
    "# print(ru_dovish)\n",
    "\n",
    "e_hawkish = searchAndCountHawkish(bigram_list, term, Employment_Hawkish)\n",
    "# print(e_hawkish)\n",
    "e_dovish = searchAndCountDovish(bigram_list, term, Employment_Dovish)\n",
    "# print(e_dovish)\n",
    "\n",
    "lm_hawkish = searchAndCountHawkish(bigram_list, term, LaborMarket_Hawkish)\n",
    "# print(lm_hawkish)\n",
    "lm_dovish = searchAndCountDovish(bigram_list, term, LaborMarket_Dovish)\n",
    "# print(lm_dovish)\n",
    "\n",
    "ue_hawkish = searchAndCountHawkish(bigram_list, term, Unemployment_Hawkish)\n",
    "# print(ue_hawkish)\n",
    "ue_dovish = searchAndCountDovish(bigram_list, term, Unemployment_Dovish)\n",
    "# print(ue_dovish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1906873614190687\n"
     ]
    }
   ],
   "source": [
    "# Calculating net hawkishness\n",
    "\n",
    "hawk = cpi_hawkish + ip_hawkish + cs_hawkish + ea_hawkish + ru_hawkish + e_hawkish + lm_hawkish + ue_hawkish\n",
    "dove = cpi_dovish + ip_dovish + cs_dovish + ea_dovish + ru_dovish + e_dovish + lm_dovish + ue_dovish\n",
    "\n",
    "net_hawkishness = 1 + ((hawk - dove) / (hawk + dove))\n",
    "\n",
    "print(net_hawkishness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the bigram_list into dictionary with the index as the key and the bigram as the value\n",
    "\n",
    "def make_bigram_dict(bigram_list):\n",
    "    bigram_dict = {}\n",
    "    for i in range(len(bigram_list)):\n",
    "        bigram_dict[i] = bigram_list[i]\n",
    "    return bigram_dict\n",
    "\n",
    "bigram_dict = make_bigram_dict(bigram_list)\n",
    "\n",
    "# dump to json in readedable format\n",
    "import json\n",
    "with open('bigram_dict.json', 'w') as fp:\n",
    "    json.dump(bigram_dict, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acceler', 'boost', 'elev', 'escal', 'high', 'highten', 'increas', 'jump', 'pickup', 'risen', 'rise', 'rose', 'runup', 'run-up', 'strong', 'surg', 'up']\n"
     ]
    }
   ],
   "source": [
    "print(ConsumerPricesInflation_Hawkish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
