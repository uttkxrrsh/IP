{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import regex as re\n",
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from deviation_dictionary import *\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "stemmer = PorterStemmer()\n",
    "os.chdir('/home/uttkarsh/IP/MPC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(file):\n",
    "    text = ''\n",
    "    with open(file, 'rb') as pdfFileObj:\n",
    "        pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "        num_pages = len(pdfReader.pages)\n",
    "        for i in range(num_pages):\n",
    "            pageObj = pdfReader.pages[i]\n",
    "            text += pageObj.extract_text()\n",
    "        text = text.replace('\\n', '')\n",
    "    return text\n",
    "\n",
    "def get_string_from_list(list):\n",
    "    string = ''\n",
    "    for i in range(len(list)):\n",
    "        string += list[i]\n",
    "        if i != len(list)-1:\n",
    "            string += ' '\n",
    "    return string\n",
    "\n",
    "def filter(text):\n",
    "    token = word_tokenize(text)\n",
    "    token = [word.lower() for word in token]\n",
    "    token = [word for word in token if word.isalpha()]\n",
    "    token = [word for word in token if (word == 'down' or not word in stop_words )]\n",
    "    # remoev single character\n",
    "    token = [word for word in token if len(word) > 1]\n",
    "    # remove th\n",
    "    token = [word for word in token if word != 'th']\n",
    "    for i in range(len(token)):\n",
    "        if token[i] == 'per' and token[i+1] == 'cent':\n",
    "            token[i] = 'percent'\n",
    "            token[i+1] = ''\n",
    "    token = [word for word in token if word != '']\n",
    "    return token\n",
    "\n",
    "def get_unigram(token):\n",
    "    token = [stemmer.stem(word) for word in token]\n",
    "    return token\n",
    "\n",
    "def get_bigram(token):\n",
    "    token = [stemmer.stem(word) for word in token]\n",
    "    bigram = ngrams(token, 2)\n",
    "    return list(bigram)\n",
    "\n",
    "def get_trigram(token):\n",
    "    token = [stemmer.stem(word) for word in token]\n",
    "    trigram = ngrams(token, 3)\n",
    "    return list(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_dict contains the words, for words with size 1 count them in the bigram list\n",
    "\n",
    "def count_1_length(unigram_list, term):\n",
    "    count = 0\n",
    "    for unigram in unigram_list:\n",
    "        if unigram == term:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def count_2_length(unigram_list, term1, term2):\n",
    "    count = 0\n",
    "    for i in range(len(unigram_list)):\n",
    "        if unigram_list[i] == term1:\n",
    "            if i-7 < 0:\n",
    "                for k in range(i+7):\n",
    "                    if unigram_list[k] == term2:\n",
    "                        count += 1\n",
    "            elif i+7 > len(unigram_list):\n",
    "                for k in range(i, len(unigram_list)):\n",
    "                    if unigram_list[k] == term2:\n",
    "                        count += 1\n",
    "            else:\n",
    "                for k in range(i-7, i+7):\n",
    "                    if unigram_list[k] == term2:\n",
    "                        count += 1\n",
    "    return count\n",
    "\n",
    "def count_length_1(bigram_list, term):\n",
    "    count = 0\n",
    "    for bigram in bigram_list:\n",
    "        if bigram[0] == term:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def count_length_2(bigram_list, term1, term2):\n",
    "    count = 0\n",
    "    for i in range(len(bigram_list)):\n",
    "        if term1 in bigram_list[i]:\n",
    "            if i-7 < 0:\n",
    "                for k in range(i+7):\n",
    "                    if term2 in bigram_list[k]:\n",
    "                        count += 1\n",
    "            elif i+7 > len(bigram_list):\n",
    "                for k in range(i, len(bigram_list)):\n",
    "                    if term2 in bigram_list[k]:\n",
    "                        count += 1\n",
    "            else:\n",
    "                for k in range(i-7, i+7):\n",
    "                    if term2 in bigram_list[k]:\n",
    "                        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_date_data(df, date):\n",
    "    year = int(date.split('-')[1])\n",
    "    month = int(date.split('-')[0])\n",
    "    new_df = df[df['Year'] == year]\n",
    "    # select only month that is either 1 or 2 months ahead\n",
    "    new_df = df[df['Month'].isin([month, month+1, month+2])]\n",
    "    # return 1st record\n",
    "    # if df empty increase the year by 1 and select the first record\n",
    "    if new_df.empty:\n",
    "        year += 1\n",
    "        new_df = df[df['Year'] == year]\n",
    "    return new_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_score(df, date, alpha):\n",
    "    new_df = nearest_date_data(df, date)\n",
    "    score = alpha*(new_df['Current'] - new_df['3m']) + pow(alpha, 4)*(new_df['Current'] - new_df['1y'])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening each file in each folder\n",
    "def make_high_low():\n",
    "\n",
    "    file_names = glob.glob('*.pdf')\n",
    "    # sort according to year filename using lambda function\n",
    "    file_names.sort(key = lambda x: x.split('-')[1])\n",
    "    print(file_names)\n",
    "    df = pd.read_excel('EHI.xlsx')\n",
    "    for file_name in file_names:\n",
    "        file_name = file_name.split('.')[0]\n",
    "        hd = {}\n",
    "        ld = {}\n",
    "        # print(file_name)\n",
    "        text = get_text(file_name + '.pdf')\n",
    "        token = filter(text)\n",
    "        # dump tokens\n",
    "        with open('tokens', 'w') as fp:\n",
    "            json.dump(token, fp, indent = 4)\n",
    "        # N = len(token)\n",
    "        string_list = get_string_from_list(token)\n",
    "        uni_list = get_unigram(token)\n",
    "        bigram_list = get_bigram(token)\n",
    "        for i in range(len(high_dict)):\n",
    "            if(len(high_dict[i].split(' ')) == 1):\n",
    "                term = high_dict[i]\n",
    "                term = stemmer.stem(term)\n",
    "                hd[high_dict[i]] = count_1_length(uni_list, high_dict[i])\n",
    "            elif(len(high_dict[i].split(' ')) == 2):\n",
    "                term1 = high_dict[i]\n",
    "                term1 = stemmer.stem(term1.split(' ')[0])\n",
    "                term2 = high_dict[i]\n",
    "                term2 = stemmer.stem(term2.split(' ')[1])\n",
    "                hd[high_dict[i]] = count_2_length(uni_list, term1, term2)\n",
    "            \n",
    "        for i in range(len(low_dict)):\n",
    "            if(len(low_dict[i].split(' ')) == 1):\n",
    "                term = low_dict[i]\n",
    "                term = stemmer.stem(term)\n",
    "                ld[low_dict[i]] = count_1_length(uni_list, low_dict[i]) \n",
    "            elif(len(low_dict[i].split(' ')) == 2):\n",
    "                term1 = low_dict[i]\n",
    "                term1 = stemmer.stem(term1.split(' ')[0])\n",
    "                term2 = low_dict[i]\n",
    "                term2 = stemmer.stem(term2.split(' ')[1])\n",
    "                ld[low_dict[i]] = count_2_length(uni_list, term1, term2)\n",
    "\n",
    "        high = sum(hd.values())\n",
    "        low = sum(ld.values())\n",
    "\n",
    "        if(high+low == 0):\n",
    "            score = 0\n",
    "            continue\n",
    "\n",
    "        score = (high-low)/(high+low)\n",
    "        \n",
    "        new_score = find_score(df, file_name, 0.5)\n",
    "        print(f\"{file_name}, {score}, {new_score}\")\n",
    "\n",
    "        final_dict = {\"high\": hd, \"low\": ld,'score': score, 'new_score': new_score}\n",
    "\n",
    "        file = file_name + '.json'\n",
    "\n",
    "        with open(file, 'w') as fp:\n",
    "            json.dump(final_dict, fp, indent = 4)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10-2016.pdf', '12-2016.pdf', '6-2017.pdf', '4-2017.pdf', '12-2017.pdf', '8-2017.pdf', '2-2017.pdf', '10-2017.pdf', '2-2018.pdf', '12-2018.pdf', '6-2018.pdf', '4-2018.pdf', '10-2018.pdf', '8-2018.pdf', '6-2019.pdf', '8-2019.pdf', '2-2019.pdf', '10-2019.pdf', '12-2019.pdf', '4-2019.pdf', '12-2020.pdf', '8-2020.pdf', '3-2020.pdf', '2-2020.pdf', '5-2020.pdf', '10-2020.pdf', '4-2020.pdf', '8-2021.pdf', '6-2021.pdf', '12-2021.pdf', '4-2021.pdf', '2-2021.pdf', '10-2021.pdf', '2-2022.pdf', '9-2022.pdf', '4-2022.pdf', '12-2022.pdf', '6-2022.pdf', '8-2022.pdf', '8-2023.pdf', '4-2023.pdf', '6-2023.pdf', '2-2023.pdf']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-2016, -0.4444444444444444, 0.18125000000000024\n",
      "12-2016, 0.16666666666666666, 0.18125000000000024\n",
      "6-2017, -0.2, -0.30625\n",
      "4-2017, 0.24324324324324326, -0.30625\n",
      "12-2017, 0.38461538461538464, 0.18125000000000024\n",
      "8-2017, -0.2830188679245283, -0.21874999999999944\n",
      "2-2017, 0.3333333333333333, -0.11249999999999982\n",
      "10-2017, 0.2727272727272727, 0.18125000000000024\n",
      "2-2018, 0.6078431372549019, -0.11249999999999982\n",
      "12-2018, 0.4375, 0.18125000000000024\n",
      "6-2018, 0.5666666666666667, -0.30625\n",
      "4-2018, 0.3333333333333333, -0.30625\n",
      "10-2018, 0.5909090909090909, 0.18125000000000024\n",
      "8-2018, 0.16981132075471697, -0.21874999999999944\n",
      "6-2019, 0.0, -0.30625\n",
      "8-2019, -1.0, -0.21874999999999944\n",
      "2-2019, -0.3333333333333333, -0.11249999999999982\n",
      "10-2019, -0.2, 0.18125000000000024\n",
      "12-2019, -0.14285714285714285, 0.18125000000000024\n",
      "4-2019, -0.42857142857142855, -0.30625\n",
      "12-2020, -1.0, 0.18125000000000024\n",
      "8-2020, -0.25, -0.21874999999999944\n",
      "3-2020, -0.6, -0.11249999999999982\n",
      "2-2020, 0.0, -0.11249999999999982\n",
      "5-2020, -0.1111111111111111, -0.30625\n",
      "10-2020, -1.0, 0.18125000000000024\n",
      "4-2020, 0.2, -0.30625\n",
      "8-2021, 0.38461538461538464, -0.21874999999999944\n",
      "6-2021, -0.4, -0.30625\n",
      "12-2021, 0.7777777777777778, 0.18125000000000024\n",
      "4-2021, 0.7142857142857143, -0.30625\n",
      "2-2021, 1.0, -0.11249999999999982\n",
      "10-2021, 0.3333333333333333, 0.18125000000000024\n",
      "2-2022, 0.45454545454545453, -0.11249999999999982\n",
      "9-2022, 0.6470588235294118, -0.21874999999999944\n",
      "4-2022, 0.8571428571428571, -0.30625\n",
      "12-2022, 0.7, 0.18125000000000024\n",
      "6-2022, 0.5238095238095238, -0.30625\n",
      "8-2022, 0.5, -0.21874999999999944\n",
      "8-2023, 0.05263157894736842, -0.21874999999999944\n",
      "4-2023, 0.1111111111111111, -0.30625\n",
      "6-2023, -0.391304347826087, -0.30625\n",
      "2-2023, 0.17647058823529413, -0.11249999999999982\n"
     ]
    }
   ],
   "source": [
    "make_high_low()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
